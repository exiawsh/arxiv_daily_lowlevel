[
    {
        "title": "OpenSR-SRGAN: A Flexible Super-Resolution Framework for Multispectral Earth Observation Data",
        "summary": "We present OpenSR-SRGAN, an open and modular framework for single-image super-resolution in Earth Observation. The software provides a unified implementation of SRGAN-style models that is easy to configure, extend, and apply to multispectral satellite data such as Sentinel-2. Instead of requiring users to modify model code, OpenSR-SRGAN exposes generators, discriminators, loss functions, and training schedules through concise configuration files, making it straightforward to switch between architectures, scale factors, and band setups. The framework is designed as a practical tool and benchmark implementation rather than a state-of-the-art model. It ships with ready-to-use configurations for common remote sensing scenarios, sensible default settings for adversarial training, and built-in hooks for logging, validation, and large-scene inference. By turning GAN-based super-resolution into a configuration-driven workflow, OpenSR-SRGAN lowers the entry barrier for researchers and practitioners who wish to experiment with SRGANs, compare models in a reproducible way, and deploy super-resolution pipelines across diverse Earth-observation datasets.",
        "url": "http://arxiv.org/abs/2511.10461v1",
        "published_date": "2025-11-13T16:28:35+00:00",
        "updated_date": "2025-11-14T01:52:43+00:00",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Simon Donike",
            "Cesar Aybar",
            "Julio Contreras",
            "Luis Gómez-Chova"
        ],
        "tldr": "The paper introduces OpenSR-SRGAN, a modular and configurable framework for single-image super-resolution of Earth Observation data using SRGAN-style models, aimed at simplifying experimentation and deployment for researchers and practitioners.",
        "tldr_zh": "该论文介绍了 OpenSR-SRGAN，一个模块化和可配置的框架，用于地球观测数据的单图像超分辨率，使用 SRGAN 风格的模型，旨在简化研究人员和从业人员的实验和部署。",
        "relevance_score": 9,
        "novelty_claim_score": 6,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 8
    },
    {
        "title": "Physically Interpretable Multi-Degradation Image Restoration via Deep Unfolding and Explainable Convolution",
        "summary": "Although image restoration has advanced significantly, most existing methods target only a single type of degradation. In real-world scenarios, images often contain multiple degradations simultaneously, such as rain, noise, and haze, requiring models capable of handling diverse degradation types. Moreover, methods that improve performance through module stacking often suffer from limited interpretability. In this paper, we propose a novel interpretability-driven approach for multi-degradation image restoration, built upon a deep unfolding network that maps the iterative process of a mathematical optimization algorithm into a learnable network structure. Specifically, we employ an improved second-order semi-smooth Newton algorithm to ensure that each module maintains clear physical interpretability. To further enhance interpretability and adaptability, we design an explainable convolution module inspired by the human brain's flexible information processing and the intrinsic characteristics of images, allowing the network to flexibly leverage learned knowledge and autonomously adjust parameters for different input. The resulting tightly integrated architecture, named InterIR, demonstrates excellent performance in multi-degradation restoration while remaining highly competitive on single-degradation tasks.",
        "url": "http://arxiv.org/abs/2511.10166v1",
        "published_date": "2025-11-13T10:27:41+00:00",
        "updated_date": "2025-11-14T01:36:49+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Hu Gao",
            "Xiaoning Lei",
            "Xichen Xu",
            "Depeng Dang",
            "Lizhuang Ma"
        ],
        "tldr": "This paper introduces InterIR, a deep unfolding network for multi-degradation image restoration that incorporates physical interpretability and explainable convolution modules for improved performance and adaptability.",
        "tldr_zh": "本文介绍了一种用于多重退化图像恢复的深度展开网络InterIR，该网络结合了物理可解释性和可解释卷积模块，以提高性能和适应性。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 8,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Equivariant Sampling for Improving Diffusion Model-based Image Restoration",
        "summary": "Recent advances in generative models, especially diffusion models, have significantly improved image restoration (IR) performance. However, existing problem-agnostic diffusion model-based image restoration (DMIR) methods face challenges in fully leveraging diffusion priors, resulting in suboptimal performance. In this paper, we address the limitations of current problem-agnostic DMIR methods by analyzing their sampling process and providing effective solutions. We introduce EquS, a DMIR method that imposes equivariant information through dual sampling trajectories. To further boost EquS, we propose the Timestep-Aware Schedule (TAS) and introduce EquS$^+$. TAS prioritizes deterministic steps to enhance certainty and sampling efficiency. Extensive experiments on benchmarks demonstrate that our method is compatible with previous problem-agnostic DMIR methods and significantly boosts their performance without increasing computational costs. Our code is available at https://github.com/FouierL/EquS.",
        "url": "http://arxiv.org/abs/2511.09965v1",
        "published_date": "2025-11-13T04:56:53+00:00",
        "updated_date": "2025-11-14T01:22:30+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Chenxu Wu",
            "Qingpeng Kong",
            "Peiang Zhao",
            "Wendi Yang",
            "Wenxin Ma",
            "Fenghe Tang",
            "Zihang Jiang",
            "S. Kevin Zhou"
        ],
        "tldr": "The paper introduces EquS, a diffusion model-based image restoration method that leverages equivariant information through dual sampling trajectories and a timestep-aware schedule to improve performance and efficiency without added computational cost.",
        "tldr_zh": "本文介绍了一种基于扩散模型的图像修复方法EquS，它通过双重采样轨迹和时间步感知调度来利用等变信息，从而提高性能和效率，而无需增加计算成本。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Learnable Total Variation with Lambda Mapping for Low-Dose CT Denoising",
        "summary": "Although Total Variation (TV) performs well in noise reduction and edge preservation on images, its dependence on the lambda parameter limits its efficiency and makes it difficult to use effectively. In this study, we present a Learnable Total Variation (LTV) framework that couples an unrolled TV solver with a data-driven Lambda Mapping Network (LambdaNet) predicting a per-pixel regularization map. The pipeline is trained end-to-end so that reconstruction and regularization are optimized jointly, yielding spatially adaptive smoothing: strong in homogeneous regions, relaxed near anatomical boundaries. Experiments on the DeepLesion dataset, using a realistic noise model adapted from the LoDoPaB-CT methodology, show consistent gains over classical TV and FBP+U-Net: +2.9 dB PSNR and +6% SSIM on average. LTV provides an interpretable alternative to black-box CNNs and a basis for 3D and data-consistency-driven reconstruction. Our codes are available at: https://github.com/itu-biai/deep_tv_for_ldct",
        "url": "http://arxiv.org/abs/2511.10500v1",
        "published_date": "2025-11-13T17:05:36+00:00",
        "updated_date": "2025-11-14T01:54:49+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Yusuf Talha Basak",
            "Mehmet Ozan Unal",
            "Metin Ertas",
            "Isa Yildirim"
        ],
        "tldr": "The paper introduces a Learnable Total Variation (LTV) framework for low-dose CT denoising, combining an unrolled TV solver with a data-driven Lambda Mapping Network to predict per-pixel regularization, achieving superior performance compared to classical TV and FBP+U-Net.",
        "tldr_zh": "该论文介绍了一种用于低剂量CT降噪的可学习全变分(LTV)框架，该框架将展开的TV求解器与数据驱动的Lambda映射网络相结合，以预测每个像素的正则化，与经典TV和FBP+U-Net相比，实现了更优越的性能。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 7
    }
]
[
    {
        "title": "Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration",
        "summary": "In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rather than limited to just the patches within an image. This enables images to be jointly denoised at inference time, learning both intra and inter-image correspondence. We observe a clear scaling effect - larger group sizes yield stronger cross-sample attention and better generation quality. Furthermore, we introduce a qualitative measure to capture this behavior and show that its strength closely correlates with FID. Built on standard diffusion transformers, our GroupDiff achieves up to 32.2% FID improvement on ImageNet-256x256. Our work reveals cross-sample inference as an effective, previously unexplored mechanism for generative modeling.",
        "url": "http://arxiv.org/abs/2512.10954v1",
        "published_date": "2025-12-11T18:59:55+00:00",
        "updated_date": "2025-12-11T18:59:55+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Sicheng Mo",
            "Thao Nguyen",
            "Richard Zhang",
            "Nick Kolkin",
            "Siddharth Srinivasan Iyer",
            "Eli Shechtman",
            "Krishna Kumar Singh",
            "Yong Jae Lee",
            "Bolei Zhou",
            "Yuheng Li"
        ],
        "tldr": "The paper introduces Group Diffusion, a novel approach to image generation that allows images to be jointly denoised by sharing the attention mechanism across samples during inference, leading to significant FID improvements.",
        "tldr_zh": "该论文介绍了 Group Diffusion，一种新颖的图像生成方法，它允许通过在推理期间跨样本共享注意力机制来联合去噪图像，从而显著提高 FID。",
        "relevance_score": 9,
        "novelty_claim_score": 9,
        "clarity_score": 8,
        "potential_impact_score": 8,
        "overall_priority_score": 9
    },
    {
        "title": "ClusIR: Towards Cluster-Guided All-in-One Image Restoration",
        "summary": "All-in-One Image Restoration (AiOIR) aims to recover high-quality images from diverse degradations within a unified framework. However, existing methods often fail to explicitly model degradation types and struggle to adapt their restoration behavior to complex or mixed degradations. To address these issues, we propose ClusIR, a Cluster-Guided Image Restoration framework that explicitly models degradation semantics through learnable clustering and propagates cluster-aware cues across spatial and frequency domains for adaptive restoration. Specifically, ClusIR comprises two key components: a Probabilistic Cluster-Guided Routing Mechanism (PCGRM) and a Degradation-Aware Frequency Modulation Module (DAFMM). The proposed PCGRM disentangles degradation recognition from expert activation, enabling discriminative degradation perception and stable expert routing. Meanwhile, DAFMM leverages the cluster-guided priors to perform adaptive frequency decomposition and targeted modulation, collaboratively refining structural and textural representations for higher restoration fidelity. The cluster-guided synergy seamlessly bridges semantic cues with frequency-domain modulation, empowering ClusIR to attain remarkable restoration results across a wide range of degradations. Extensive experiments on diverse benchmarks validate that ClusIR reaches competitive performance under several scenarios.",
        "url": "http://arxiv.org/abs/2512.10948v1",
        "published_date": "2025-12-11T18:59:47+00:00",
        "updated_date": "2025-12-11T18:59:47+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Shengkai Hu",
            "Jiaqi Ma",
            "Jun Wan",
            "Wenwen Min",
            "Yongcheng Jing",
            "Lefei Zhang",
            "Dacheng Tao"
        ],
        "tldr": "The paper introduces ClusIR, a novel All-in-One Image Restoration framework that uses cluster-guided degradation semantics to improve restoration performance across various degradation types by adaptively modulating spatial and frequency domains.",
        "tldr_zh": "该论文介绍了ClusIR，一种新颖的All-in-One图像修复框架，它利用聚类引导的退化语义来提高各种退化类型的修复性能，通过自适应地调节空间和频率域。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]
[
    {
        "title": "SD3.5-Flash: Distribution-Guided Distillation of Generative Flows",
        "summary": "We present SD3.5-Flash, an efficient few-step distillation framework that\nbrings high-quality image generation to accessible consumer devices. Our\napproach distills computationally prohibitive rectified flow models through a\nreformulated distribution matching objective tailored specifically for few-step\ngeneration. We introduce two key innovations: \"timestep sharing\" to reduce\ngradient noise and \"split-timestep fine-tuning\" to improve prompt alignment.\nCombined with comprehensive pipeline optimizations like text encoder\nrestructuring and specialized quantization, our system enables both rapid\ngeneration and memory-efficient deployment across different hardware\nconfigurations. This democratizes access across the full spectrum of devices,\nfrom mobile phones to desktop computers. Through extensive evaluation including\nlarge-scale user studies, we demonstrate that SD3.5-Flash consistently\noutperforms existing few-step methods, making advanced generative AI truly\naccessible for practical deployment.",
        "url": "http://arxiv.org/abs/2509.21318v1",
        "published_date": "2025-09-25T16:07:38+00:00",
        "updated_date": "2025-09-25T16:07:38+00:00",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Hmrishav Bandyopadhyay",
            "Rahim Entezari",
            "Jim Scott",
            "Reshinth Adithyan",
            "Yi-Zhe Song",
            "Varun Jampani"
        ],
        "tldr": "SD3.5-Flash is a framework for efficient, high-quality image generation on consumer devices using distribution-guided distillation of rectified flow models with innovations like timestep sharing and split-timestep fine-tuning.",
        "tldr_zh": "SD3.5-Flash是一个高效的图像生成框架，通过分布引导的修正流模型蒸馏，在消费级设备上实现高质量图像生成，并采用了时间步共享和分裂时间步微调等创新技术。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 9,
        "overall_priority_score": 9
    },
    {
        "title": "MedVSR: Medical Video Super-Resolution with Cross State-Space Propagation",
        "summary": "High-resolution (HR) medical videos are vital for accurate diagnosis, yet are\nhard to acquire due to hardware limitations and physiological constraints.\nClinically, the collected low-resolution (LR) medical videos present unique\nchallenges for video super-resolution (VSR) models, including camera shake,\nnoise, and abrupt frame transitions, which result in significant optical flow\nerrors and alignment difficulties. Additionally, tissues and organs exhibit\ncontinuous and nuanced structures, but current VSR models are prone to\nintroducing artifacts and distorted features that can mislead doctors. To this\nend, we propose MedVSR, a tailored framework for medical VSR. It first employs\nCross State-Space Propagation (CSSP) to address the imprecise alignment by\nprojecting distant frames as control matrices within state-space models,\nenabling the selective propagation of consistent and informative features to\nneighboring frames for effective alignment. Moreover, we design an Inner\nState-Space Reconstruction (ISSR) module that enhances tissue structures and\nreduces artifacts with joint long-range spatial feature learning and\nlarge-kernel short-range information aggregation. Experiments across four\ndatasets in diverse medical scenarios, including endoscopy and cataract\nsurgeries, show that MedVSR significantly outperforms existing VSR models in\nreconstruction performance and efficiency. Code released at\nhttps://github.com/CUHK-AIM-Group/MedVSR.",
        "url": "http://arxiv.org/abs/2509.21265v1",
        "published_date": "2025-09-25T14:56:59+00:00",
        "updated_date": "2025-09-25T14:56:59+00:00",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Xinyu Liu",
            "Guolei Sun",
            "Cheng Wang",
            "Yixuan Yuan",
            "Ender Konukoglu"
        ],
        "tldr": "The paper introduces MedVSR, a novel video super-resolution framework tailored for medical videos, utilizing Cross State-Space Propagation (CSSP) and Inner State-Space Reconstruction (ISSR) to address alignment issues and enhance tissue structure.",
        "tldr_zh": "该论文介绍了MedVSR，一种为医疗视频定制的新型视频超分辨率框架，它利用跨状态空间传播（CSSP）和内部状态空间重建（ISSR）来解决对齐问题并增强组织结构。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Nuclear Diffusion Models for Low-Rank Background Suppression in Videos",
        "summary": "Video sequences often contain structured noise and background artifacts that\nobscure dynamic content, posing challenges for accurate analysis and\nrestoration. Robust principal component methods address this by decomposing\ndata into low-rank and sparse components. Still, the sparsity assumption often\nfails to capture the rich variability present in real video data. To overcome\nthis limitation, a hybrid framework that integrates low-rank temporal modeling\nwith diffusion posterior sampling is proposed. The proposed method, Nuclear\nDiffusion, is evaluated on a real-world medical imaging problem, namely cardiac\nultrasound dehazing, and demonstrates improved dehazing performance compared to\ntraditional RPCA concerning contrast enhancement (gCNR) and signal preservation\n(KS statistic). These results highlight the potential of combining model-based\ntemporal models with deep generative priors for high-fidelity video\nrestoration.",
        "url": "http://arxiv.org/abs/2509.20886v1",
        "published_date": "2025-09-25T08:20:22+00:00",
        "updated_date": "2025-09-25T08:20:22+00:00",
        "categories": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "authors": [
            "Tristan S. W. Stevens",
            "Oisín Nolan",
            "Jean-Luc Robert",
            "Ruud J. G. van Sloun"
        ],
        "tldr": "This paper proposes a hybrid low-rank and diffusion model called Nuclear Diffusion for video background suppression, demonstrating improved performance in cardiac ultrasound dehazing compared to traditional RPCA methods.",
        "tldr_zh": "本文提出了一种混合低秩和扩散模型，名为 Nuclear Diffusion，用于视频背景抑制，并在心脏超声去雾方面表现出比传统 RPCA 方法更好的性能。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 7
    }
]
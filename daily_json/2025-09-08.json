[
    {
        "title": "BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models",
        "summary": "Recent advancements in aligning image and video generative models via GRPO\nhave achieved remarkable gains in enhancing human preference alignment.\nHowever, these methods still face high computational costs from on-policy\nrollouts and excessive SDE sampling steps, as well as training instability due\nto sparse rewards. In this paper, we propose BranchGRPO, a novel method that\nintroduces a branch sampling policy updating the SDE sampling process. By\nsharing computation across common prefixes and pruning low-reward paths and\nredundant depths, BranchGRPO substantially lowers the per-update compute cost\nwhile maintaining or improving exploration diversity. This work makes three\nmain contributions: (1) a branch sampling scheme that reduces rollout and\ntraining cost; (2) a tree-based advantage estimator incorporating dense\nprocess-level rewards; and (3) pruning strategies exploiting path and depth\nredundancy to accelerate convergence and boost performance. Experiments on\nimage and video preference alignment show that BranchGRPO improves alignment\nscores by 16% over strong baselines, while cutting training time by 50%.",
        "url": "http://arxiv.org/abs/2509.06040v1",
        "published_date": "2025-09-07T12:53:06+00:00",
        "updated_date": "2025-09-07T12:53:06+00:00",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yuming Li",
            "Yikai Wang",
            "Yuying Zhu",
            "Zhongyu Zhao",
            "Ming Lu",
            "Qi She",
            "Shanghang Zhang"
        ],
        "tldr": "The paper introduces BranchGRPO, a novel method for aligning image and video generative models via GRPO, which reduces computational costs and improves training stability through a branch sampling scheme, tree-based advantage estimator, and pruning strategies.",
        "tldr_zh": "该论文介绍了一种名为BranchGRPO的新方法，用于通过GRPO对齐图像和视频生成模型，通过分支抽样方案、基于树的优势估计器和剪枝策略，降低了计算成本并提高了训练稳定性。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]
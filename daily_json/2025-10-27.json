[
    {
        "title": "SRSR: Enhancing Semantic Accuracy in Real-World Image Super-Resolution with Spatially Re-Focused Text-Conditioning",
        "summary": "Existing diffusion-based super-resolution approaches often exhibit semantic\nambiguities due to inaccuracies and incompleteness in their text conditioning,\ncoupled with the inherent tendency for cross-attention to divert towards\nirrelevant pixels. These limitations can lead to semantic misalignment and\nhallucinated details in the generated high-resolution outputs. To address\nthese, we propose a novel, plug-and-play spatially re-focused super-resolution\n(SRSR) framework that consists of two core components: first, we introduce\nSpatially Re-focused Cross-Attention (SRCA), which refines text conditioning at\ninference time by applying visually-grounded segmentation masks to guide\ncross-attention. Second, we introduce a Spatially Targeted Classifier-Free\nGuidance (STCFG) mechanism that selectively bypasses text influences on\nungrounded pixels to prevent hallucinations. Extensive experiments on both\nsynthetic and real-world datasets demonstrate that SRSR consistently\noutperforms seven state-of-the-art baselines in standard fidelity metrics (PSNR\nand SSIM) across all datasets, and in perceptual quality measures (LPIPS and\nDISTS) on two real-world benchmarks, underscoring its effectiveness in\nachieving both high semantic fidelity and perceptual quality in\nsuper-resolution.",
        "url": "http://arxiv.org/abs/2510.22534v1",
        "published_date": "2025-10-26T05:03:55+00:00",
        "updated_date": "2025-10-26T05:03:55+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Chen Chen",
            "Majid Abdolshah",
            "Violetta Shevchenko",
            "Hongdong Li",
            "Chang Xu",
            "Pulak Purkait"
        ],
        "tldr": "This paper introduces SRSR, a plug-and-play framework that enhances semantic accuracy in diffusion-based image super-resolution by using spatially re-focused text conditioning via visually-grounded segmentation masks and spatially targeted classifier-free guidance, demonstrating improved fidelity and perceptual quality.",
        "tldr_zh": "该论文介绍了一种名为SRSR的即插即用框架，通过使用空间重聚焦的文本条件，利用视觉接地的分割掩码和空间目标分类器自由引导，增强了基于扩散的图像超分辨率的语义准确性，并展示了改进的保真度和感知质量。",
        "relevance_score": 10,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 9
    }
]
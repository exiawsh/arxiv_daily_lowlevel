[
    {
        "title": "Towards Redundancy Reduction in Diffusion Models for Efficient Video Super-Resolution",
        "summary": "Diffusion models have recently shown promising results for video\nsuper-resolution (VSR). However, directly adapting generative diffusion models\nto VSR can result in redundancy, since low-quality videos already preserve\nsubstantial content information. Such redundancy leads to increased\ncomputational overhead and learning burden, as the model performs superfluous\noperations and must learn to filter out irrelevant information. To address this\nproblem, we propose OASIS, an efficient $\\textbf{o}$ne-step diffusion model\nwith $\\textbf{a}$ttention $\\textbf{s}$pecialization for real-world\nv$\\textbf{i}$deo $\\textbf{s}$uper-resolution. OASIS incorporates an attention\nspecialization routing that assigns attention heads to different patterns\naccording to their intrinsic behaviors. This routing mitigates redundancy while\neffectively preserving pretrained knowledge, allowing diffusion models to\nbetter adapt to VSR and achieve stronger performance. Moreover, we propose a\nsimple yet effective progressive training strategy, which starts with\ntemporally consistent degradations and then shifts to inconsistent settings.\nThis strategy facilitates learning under complex degradations. Extensive\nexperiments demonstrate that OASIS achieves state-of-the-art performance on\nboth synthetic and real-world datasets. OASIS also provides superior inference\nspeed, offering a $\\textbf{6.2$\\times$}$ speedup over one-step diffusion\nbaselines such as SeedVR2. The code will be available at\n\\href{https://github.com/jp-guo/OASIS}{https://github.com/jp-guo/OASIS}.",
        "url": "http://arxiv.org/abs/2509.23980v1",
        "published_date": "2025-09-28T17:08:51+00:00",
        "updated_date": "2025-09-28T17:08:51+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Jinpei Guo",
            "Yifei Ji",
            "Zheng Chen",
            "Yufei Wang",
            "Sizhuo Ma",
            "Yong Guo",
            "Yulun Zhang",
            "Jian Wang"
        ]
    },
    {
        "title": "HunyuanImage 3.0 Technical Report",
        "summary": "We present HunyuanImage 3.0, a native multimodal model that unifies\nmultimodal understanding and generation within an autoregressive framework,\nwith its image generation module publicly available. The achievement of\nHunyuanImage 3.0 relies on several key components, including meticulous data\ncuration, advanced architecture design, a native Chain-of-Thoughts schema,\nprogressive model pre-training, aggressive model post-training, and an\nefficient infrastructure that enables large-scale training and inference. With\nthese advancements, we successfully trained a Mixture-of-Experts (MoE) model\ncomprising over 80 billion parameters in total, with 13 billion parameters\nactivated per token during inference, making it the largest and most powerful\nopen-source image generative model to date. We conducted extensive experiments\nand the results of automatic and human evaluation of text-image alignment and\nvisual quality demonstrate that HunyuanImage 3.0 rivals previous\nstate-of-the-art models. By releasing the code and weights of HunyuanImage 3.0,\nwe aim to enable the community to explore new ideas with a state-of-the-art\nfoundation model, fostering a dynamic and vibrant multimodal ecosystem. All\nopen source assets are publicly available at\nhttps://github.com/Tencent-Hunyuan/HunyuanImage-3.0",
        "url": "http://arxiv.org/abs/2509.23951v1",
        "published_date": "2025-09-28T16:14:10+00:00",
        "updated_date": "2025-09-28T16:14:10+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Siyu Cao",
            "Hangting Chen",
            "Peng Chen",
            "Yiji Cheng",
            "Yutao Cui",
            "Xinchi Deng",
            "Ying Dong",
            "Kipper Gong",
            "Tianpeng Gu",
            "Xiusen Gu",
            "Tiankai Hang",
            "Duojun Huang",
            "Jie Jiang",
            "Zhengkai Jiang",
            "Weijie Kong",
            "Changlin Li",
            "Donghao Li",
            "Junzhe Li",
            "Xin Li",
            "Yang Li",
            "Zhenxi Li",
            "Zhimin Li",
            "Jiaxin Lin",
            "Linus",
            "Lucaz Liu",
            "Shu Liu",
            "Songtao Liu",
            "Yu Liu",
            "Yuhong Liu",
            "Yanxin Long",
            "Fanbin Lu",
            "Qinglin Lu",
            "Yuyang Peng",
            "Yuanbo Peng",
            "Xiangwei Shen",
            "Yixuan Shi",
            "Jiale Tao",
            "Yangyu Tao",
            "Qi Tian",
            "Pengfei Wan",
            "Chunyu Wang",
            "Kai Wang",
            "Lei Wang",
            "Linqing Wang",
            "Lucas Wang",
            "Qixun Wang",
            "Weiyan Wang",
            "Hao Wen",
            "Bing Wu",
            "Jianbing Wu",
            "Yue Wu",
            "Senhao Xie",
            "Fang Yang",
            "Miles Yang",
            "Xiaofeng Yang",
            "Xuan Yang",
            "Zhantao Yang",
            "Jingmiao Yu",
            "Zheng Yuan",
            "Chao Zhang",
            "Jian-Wei Zhang",
            "Peizhen Zhang",
            "Shi-Xue Zhang",
            "Tao Zhang",
            "Weigang Zhang",
            "Yepeng Zhang",
            "Yingfang Zhang",
            "Zihao Zhang",
            "Zijian Zhang",
            "Penghao Zhao",
            "Zhiyuan Zhao",
            "Xuefei Zhe",
            "Jianchen Zhu",
            "Zhao Zhong"
        ]
    }
]
[
    {
        "title": "Sim2Real SAR Image Restoration: Metadata-Driven Models for Joint Despeckling and Sidelobes Reduction",
        "summary": "Synthetic aperture radar (SAR) provides valuable information about the Earth's surface under all weather and illumination conditions. However, the inherent phenomenon of speckle and the presence of sidelobes around bright targets pose challenges for accurate interpretation of SAR imagery. Most existing SAR image restoration methods address despeckling and sidelobes reduction as separate tasks. In this paper, we propose a unified framework that jointly performs both tasks using neural networks (NNs) trained on a realistic SAR simulated dataset generated with MOCEM. Inference can then be performed on real SAR images, demonstrating effective simulation to real (Sim2Real) transferability. Additionally, we incorporate acquisition metadata as auxiliary input to the NNs, demonstrating improved restoration performance.",
        "url": "http://arxiv.org/abs/2601.01541v1",
        "published_date": "2026-01-04T14:32:04+00:00",
        "updated_date": "2026-01-04T14:32:04+00:00",
        "categories": [
            "eess.IV",
            "cs.CV",
            "eess.SP"
        ],
        "authors": [
            "Antoine De Paepe",
            "Pascal Nguyen",
            "Michael Mabelle",
            "Cédric Saleun",
            "Antoine Jouadé",
            "Jean-Christophe Louvigne"
        ],
        "tldr": "This paper presents a Sim2Real framework for joint SAR image despeckling and sidelobe reduction using metadata-driven neural networks, trained on a realistic simulated SAR dataset.",
        "tldr_zh": "本文提出了一种Sim2Real框架，使用元数据驱动的神经网络，在逼真的模拟SAR数据集上训练，用于联合SAR图像去噪和旁瓣抑制。",
        "relevance_score": 8,
        "novelty_claim_score": 7,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 8
    },
    {
        "title": "SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution",
        "summary": "Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.",
        "url": "http://arxiv.org/abs/2601.01406v1",
        "published_date": "2026-01-04T07:04:46+00:00",
        "updated_date": "2026-01-04T07:04:46+00:00",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Habiba Kausar",
            "Saeed Anwar",
            "Omar Jamal Hammad",
            "Abdul Bais"
        ],
        "tldr": "The paper introduces SwinIFS, a landmark-guided Swin Transformer-based framework for face super-resolution that focuses on identity preservation and achieves state-of-the-art results, especially at high upscaling factors.",
        "tldr_zh": "该论文介绍了SwinIFS，一个基于 Landmark 指导的 Swin Transformer 的人脸超分辨率框架，专注于身份保持，并取得了最先进的结果，尤其是在高放大倍数下。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Improving Flexible Image Tokenizers for Autoregressive Image Generation",
        "summary": "Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \\textbf{ReToK}, a flexible tokenizer with \\underline{Re}dundant \\underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \\textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \\textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \\href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}",
        "url": "http://arxiv.org/abs/2601.01535v1",
        "published_date": "2026-01-04T14:11:45+00:00",
        "updated_date": "2026-01-04T14:11:45+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Zixuan Fu",
            "Lanqing Guo",
            "Chong Wang",
            "Binbin Song",
            "Ding Liu",
            "Bihan Wen"
        ],
        "tldr": "This paper introduces ReTok, a novel flexible image tokenizer using redundant token padding and hierarchical semantic regularization to improve autoregressive image generation by addressing information concentration in early tokens.",
        "tldr_zh": "本文介绍了 ReTok，一种新颖的灵活图像分词器，它使用冗余 token 填充和分层语义正则化来改进自回归图像生成，解决了早期 token 中的信息集中问题。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 7
    }
]
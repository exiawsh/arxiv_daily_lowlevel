[
    {
        "title": "SDAKD: Student Discriminator Assisted Knowledge Distillation for Super-Resolution Generative Adversarial Networks",
        "summary": "Generative Adversarial Networks (GANs) achieve excellent performance in\ngenerative tasks, such as image super-resolution, but their computational\nrequirements make difficult their deployment on resource-constrained devices.\nWhile knowledge distillation is a promising research direction for GAN\ncompression, effectively training a smaller student generator is challenging\ndue to the capacity mismatch between the student generator and the teacher\ndiscriminator. In this work, we propose Student Discriminator Assisted\nKnowledge Distillation (SDAKD), a novel GAN distillation methodology that\nintroduces a student discriminator to mitigate this capacity mismatch. SDAKD\nfollows a three-stage training strategy, and integrates an adapted feature map\ndistillation approach in its last two training stages. We evaluated SDAKD on\ntwo well-performing super-resolution GANs, GCFSR and Real-ESRGAN. Our\nexperiments demonstrate consistent improvements over the baselines and SOTA GAN\nknowledge distillation methods. The SDAKD source code will be made openly\navailable upon acceptance of the paper.",
        "url": "http://arxiv.org/abs/2510.03870v1",
        "published_date": "2025-10-04T16:40:18+00:00",
        "updated_date": "2025-10-04T16:40:18+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Nikolaos Kaparinos",
            "Vasileios Mezaris"
        ],
        "tldr": "The paper introduces Student Discriminator Assisted Knowledge Distillation (SDAKD) for compressing super-resolution GANs, addressing the capacity mismatch between student generator and teacher discriminator. It reports improvements over existing methods on GCFSR and Real-ESRGAN.",
        "tldr_zh": "该论文介绍了学生判别器辅助知识蒸馏（SDAKD）方法，用于压缩超分辨率GAN，解决了学生生成器和教师判别器之间的容量不匹配问题。实验表明，该方法在GCFSR和Real-ESRGAN上优于现有方法。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Denoising of Two-Phase Optically Sectioned Structured Illumination Reconstructions Using Encoder-Decoder Networks",
        "summary": "Structured illumination (SI) enhances image resolution and contrast by\nprojecting patterned light onto a sample. In two-phase optical-sectioning SI\n(OS-SI), reduced acquisition time introduces residual artifacts that\nconventional denoising struggles to suppress. Deep learning offers an\nalternative to traditional methods; however, supervised training is limited by\nthe lack of clean, optically sectioned ground-truth data. We investigate\nencoder-decoder networks for artifact reduction in two-phase OS-SI, using\nsynthetic training pairs formed by applying real artifact fields to synthetic\nimages. An asymmetrical denoising autoencoder (DAE) and a U-Net are trained on\nthe synthetic data, then evaluated on real OS-SI images. Both networks improve\nimage clarity, with each excelling against different artifact types. These\nresults demonstrate that synthetic training enables supervised denoising of\nOS-SI images and highlight the potential of encoder-decoder networks to\nstreamline reconstruction workflows.",
        "url": "http://arxiv.org/abs/2510.03452v1",
        "published_date": "2025-10-03T19:19:42+00:00",
        "updated_date": "2025-10-03T19:19:42+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Allison Davis",
            "Yezhi Shen",
            "Xiaoyu Ji",
            "Fengqing Zhu"
        ],
        "tldr": "This paper explores using encoder-decoder networks, trained on synthetic data, to denoise two-phase optical-sectioning structured illumination (OS-SI) images, addressing the challenge of limited clean ground truth data.",
        "tldr_zh": "该论文探索使用在合成数据上训练的编码器-解码器网络来对两相光学切片结构照明 (OS-SI) 图像进行去噪，从而解决了缺乏干净真实数据的问题。",
        "relevance_score": 7,
        "novelty_claim_score": 6,
        "clarity_score": 8,
        "potential_impact_score": 7,
        "overall_priority_score": 7
    }
]
[
    {
        "title": "BIR-Adapter: A Low-Complexity Diffusion Model Adapter for Blind Image Restoration",
        "summary": "This paper introduces BIR-Adapter, a low-complexity blind image restoration\nadapter for diffusion models. The BIR-Adapter enables the utilization of the\nprior of pre-trained large-scale diffusion models on blind image restoration\nwithout training any auxiliary feature extractor. We take advantage of the\nrobustness of pretrained models. We extract features from degraded images via\nthe model itself and extend the self-attention mechanism with these degraded\nfeatures. We introduce a sampling guidance mechanism to reduce hallucinations.\nWe perform experiments on synthetic and real-world degradations and demonstrate\nthat BIR-Adapter achieves competitive or better performance compared to\nstate-of-the-art methods while having significantly lower complexity.\nAdditionally, its adapter-based design enables integration into other diffusion\nmodels, enabling broader applications in image restoration tasks. We showcase\nthis by extending a super-resolution-only model to perform better under\nadditional unknown degradations.",
        "url": "http://arxiv.org/abs/2509.06904v1",
        "published_date": "2025-09-08T17:22:18+00:00",
        "updated_date": "2025-09-08T17:22:18+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Cem Eteke",
            "Alexander Griessel",
            "Wolfgang Kellerer",
            "Eckehard Steinbach"
        ],
        "tldr": "The paper introduces BIR-Adapter, a low-complexity adapter for diffusion models that improves blind image restoration by leveraging pre-trained models without auxiliary feature extractors and reduces hallucinations through sampling guidance. It achieves competitive performance with lower complexity and broader applicability.",
        "tldr_zh": "该论文介绍了一种低复杂度的盲图像恢复适配器BIR-Adapter，它利用预训练扩散模型的先验知识，无需额外的特征提取器，并通过采样引导减少幻觉。BIR-Adapter在实现具有竞争力的性能的同时，具有更低的复杂度和更广泛的适用性。",
        "relevance_score": 10,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 9,
        "overall_priority_score": 9
    },
    {
        "title": "MIORe & VAR-MIORe: Benchmarks to Push the Boundaries of Restoration",
        "summary": "We introduce MIORe and VAR-MIORe, two novel multi-task datasets that address\ncritical limitations in current motion restoration benchmarks. Designed with\nhigh-frame-rate (1000 FPS) acquisition and professional-grade optics, our\ndatasets capture a broad spectrum of motion scenarios, which include complex\nego-camera movements, dynamic multi-subject interactions, and depth-dependent\nblur effects. By adaptively averaging frames based on computed optical flow\nmetrics, MIORe generates consistent motion blur, and preserves sharp inputs for\nvideo frame interpolation and optical flow estimation. VAR-MIORe further\nextends by spanning a variable range of motion magnitudes, from minimal to\nextreme, establishing the first benchmark to offer explicit control over motion\namplitude. We provide high-resolution, scalable ground truths that challenge\nexisting algorithms under both controlled and adverse conditions, paving the\nway for next-generation research of various image and video restoration tasks.",
        "url": "http://arxiv.org/abs/2509.06803v1",
        "published_date": "2025-09-08T15:34:31+00:00",
        "updated_date": "2025-09-08T15:34:31+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "George Ciubotariu",
            "Zhuyun Zhou",
            "Zongwei Wu",
            "Radu Timofte"
        ],
        "tldr": "The paper introduces two new high-frame-rate datasets, MIORe and VAR-MIORe, for benchmarking motion restoration algorithms, offering controlled motion blur and variable motion magnitudes.",
        "tldr_zh": "该论文介绍了两个新的高帧率数据集 MIORe 和 VAR-MIORe，用于测试运动恢复算法，提供了可控的运动模糊和可变的运动幅度。",
        "relevance_score": 8,
        "novelty_claim_score": 9,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Your Super Resolution Model is not Enough for Tackling Real-World Scenarios",
        "summary": "Despite remarkable progress in Single Image Super-Resolution (SISR),\ntraditional models often struggle to generalize across varying scale factors,\nlimiting their real-world applicability. To address this, we propose a plug-in\nScale-Aware Attention Module (SAAM) designed to retrofit modern fixed-scale SR\nmodels with the ability to perform arbitrary-scale SR. SAAM employs\nlightweight, scale-adaptive feature extraction and upsampling, incorporating\nthe Simple parameter-free Attention Module (SimAM) for efficient guidance and\ngradient variance loss to enhance sharpness in image details. Our method\nintegrates seamlessly into multiple state-of-the-art SR backbones (e.g., SCNet,\nHiT-SR, OverNet), delivering competitive or superior performance across a wide\nrange of integer and non-integer scale factors. Extensive experiments on\nbenchmark datasets demonstrate that our approach enables robust multi-scale\nupscaling with minimal computational overhead, offering a practical solution\nfor real-world scenarios.",
        "url": "http://arxiv.org/abs/2509.06387v1",
        "published_date": "2025-09-08T07:13:58+00:00",
        "updated_date": "2025-09-08T07:13:58+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Dongsik Yoon",
            "Jongeun Kim"
        ],
        "tldr": "The paper introduces a Scale-Aware Attention Module (SAAM) that can be plugged into existing SR models to enable arbitrary-scale super-resolution, improving their applicability to real-world scenarios with varying scale factors. It achieves this through scale-adaptive feature extraction and upsampling with minimal overhead.",
        "tldr_zh": "该论文介绍了一种可插入现有SR模型的尺度感知注意力模块（SAAM），以实现任意尺度的超分辨率，从而提高其在具有不同尺度因子的实际场景中的适用性。它通过尺度自适应特征提取和上采样来实现，且开销极小。",
        "relevance_score": 9,
        "novelty_claim_score": 7,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "AIM 2025 Challenge on High FPS Motion Deblurring: Methods and Results",
        "summary": "This paper presents a comprehensive review of the AIM 2025 High FPS\nNon-Uniform Motion Deblurring Challenge, highlighting the proposed solutions\nand final results. The objective of this challenge is to identify effective\nnetworks capable of producing clearer and visually compelling images in diverse\nand challenging conditions, by learning representative visual cues for complex\naggregations of motion types. A total of 68 participants registered for the\ncompetition, and 9 teams ultimately submitted valid entries. This paper\nthoroughly evaluates the state-of-the-art advances in high-FPS single image\nmotion deblurring, showcasing the significant progress in the field, while\nleveraging samples of the novel dataset, MIORe, that introduces challenging\nexamples of movement patterns.",
        "url": "http://arxiv.org/abs/2509.06793v1",
        "published_date": "2025-09-08T15:22:35+00:00",
        "updated_date": "2025-09-08T15:22:35+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "George Ciubotariu",
            "Florin-Alexandru Vasluianu",
            "Zhuyun Zhou",
            "Nancy Mehta",
            "Radu Timofte",
            "Ke Wu",
            "Long Sun",
            "Lingshun Kong",
            "Zhongbao Yang",
            "Jinshan Pan",
            "Jiangxin Dong",
            "Jinhui Tang",
            "Hao Chen",
            "Yinghui Fang",
            "Dafeng Zhang",
            "Yongqi Song",
            "Jiangbo Guo",
            "Shuhua Jin",
            "Zeyu Xiao",
            "Rui Zhao",
            "Zhuoyuan Li",
            "Cong Zhang",
            "Yufeng Peng",
            "Xin Lu",
            "Zhijing Sun",
            "Chengjie Ge",
            "Zihao Li",
            "Zishun Liao",
            "Ziang Zhou",
            "Qiyu Kang",
            "Xueyang Fu",
            "Zheng-Jun Zha",
            "Yuqian Zhang",
            "Shuai Liu",
            "Jie Liu",
            "Zhuhao Zhang",
            "Lishen Qu",
            "Zhihao Liu",
            "Shihao Zhou",
            "Yaqi Luo",
            "Juncheng Zhou",
            "Jufeng Yang",
            "Qianfeng Yang",
            "Qiyuan Guan",
            "Xiang Chen",
            "Guiyue Jin",
            "Jiyu Jin"
        ],
        "tldr": "This paper summarizes the AIM 2025 High FPS Motion Deblurring Challenge, showcasing the submitted solutions, results, and the MIORe dataset. It highlights progress in high-FPS single image motion deblurring.",
        "tldr_zh": "本文总结了AIM 2025高帧率运动去模糊挑战赛，展示了提交的解决方案、结果以及MIORe数据集。它强调了高帧率单图像运动去模糊领域的进展。",
        "relevance_score": 7,
        "novelty_claim_score": 6,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 7
    }
]
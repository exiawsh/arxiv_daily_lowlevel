[
    {
        "title": "SimpleCall: A Lightweight Image Restoration Agent in Label-Free Environments with MLLM Perceptual Feedback",
        "summary": "Complex image restoration aims to recover high-quality images from inputs affected by multiple degradations such as blur, noise, rain, and compression artifacts. Recent restoration agents, powered by vision-language models and large language models, offer promising restoration capabilities but suffer from significant efficiency bottlenecks due to reflection, rollback, and iterative tool searching. Moreover, their performance heavily depends on degradation recognition models that require extensive annotations for training, limiting their applicability in label-free environments. To address these limitations, we propose a policy optimization-based restoration framework that learns an lightweight agent to determine tool-calling sequences. The agent operates in a sequential decision process, selecting the most appropriate restoration operation at each step to maximize final image quality. To enable training within label-free environments, we introduce a novel reward mechanism driven by multimodal large language models, which act as human-aligned evaluator and provide perceptual feedback for policy improvement. Once trained, our agent executes a deterministic restoration plans without redundant tool invocations, significantly accelerating inference while maintaining high restoration quality. Extensive experiments show that despite using no supervision, our method matches SOTA performance on full-reference metrics and surpasses existing approaches on no-reference metrics across diverse degradation scenarios.",
        "url": "http://arxiv.org/abs/2512.18599v1",
        "published_date": "2025-12-21T05:12:25+00:00",
        "updated_date": "2025-12-21T05:12:25+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Jianglin Lu",
            "Yuanwei Wu",
            "Ziyi Zhao",
            "Hongcheng Wang",
            "Felix Jimenez",
            "Abrar Majeedi",
            "Yun Fu"
        ],
        "tldr": "The paper introduces a lightweight image restoration agent trained via policy optimization and MLLM-based reward in label-free environments, achieving SOTA performance without requiring extensive annotated data.",
        "tldr_zh": "本文提出了一种轻量级的图像修复代理，该代理通过策略优化和基于MLLM的奖励在无标签环境下进行训练，无需大量标注数据即可实现SOTA性能。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 9
    },
    {
        "title": "MaskFocus: Focusing Policy Optimization on Critical Steps for Masked Image Generation",
        "summary": "Reinforcement learning (RL) has demonstrated significant potential for post-training language models and autoregressive visual generative models, but adapting RL to masked generative models remains challenging. The core factor is that policy optimization requires accounting for the probability likelihood of each step due to its multi-step and iterative refinement process. This reliance on entire sampling trajectories introduces high computational cost, whereas natively optimizing random steps often yields suboptimal results. In this paper, we present MaskFocus, a novel RL framework that achieves effective policy optimization for masked generative models by focusing on critical steps. Specifically, we determine the step-level information gain by measuring the similarity between the intermediate images at each sampling step and the final generated image. Crucially, we leverage this to identify the most critical and valuable steps and execute focused policy optimization on them. Furthermore, we design a dynamic routing sampling mechanism based on entropy to encourage the model to explore more valuable masking strategies for samples with low entropy. Extensive experiments on multiple Text-to-Image benchmarks validate the effectiveness of our method.",
        "url": "http://arxiv.org/abs/2512.18766v1",
        "published_date": "2025-12-21T15:08:31+00:00",
        "updated_date": "2025-12-21T15:08:31+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Guohui Zhang",
            "Hu Yu",
            "Xiaoxiao Ma",
            "Yaning Pan",
            "Hang Xu",
            "Feng Zhao"
        ],
        "tldr": "The paper introduces MaskFocus, a reinforcement learning framework for masked image generation that focuses policy optimization on critical steps identified by measuring information gain between intermediate and final images, along with a dynamic routing sampling mechanism.",
        "tldr_zh": "该论文介绍了一种名为MaskFocus的强化学习框架，用于掩码图像生成。该框架通过测量中间图像和最终图像之间的信息增益来识别关键步骤，并将策略优化集中在这些关键步骤上，同时还设计了一个动态路由采样机制。",
        "relevance_score": 8,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 8
    },
    {
        "title": "Rectification Reimagined: A Unified Mamba Model for Image Correction and Rectangling with Prompts",
        "summary": "Image correction and rectangling are valuable tasks in practical photography systems such as smartphones. Recent remarkable advancements in deep learning have undeniably brought about substantial performance improvements in these fields. Nevertheless, existing methods mainly rely on task-specific architectures. This significantly restricts their generalization ability and effective application across a wide range of different tasks. In this paper, we introduce the Unified Rectification Framework (UniRect), a comprehensive approach that addresses these practical tasks from a consistent distortion rectification perspective. Our approach incorporates various task-specific inverse problems into a general distortion model by simulating different types of lenses. To handle diverse distortions, UniRect adopts one task-agnostic rectification framework with a dual-component structure: a {Deformation Module}, which utilizes a novel Residual Progressive Thin-Plate Spline (RP-TPS) model to address complex geometric deformations, and a subsequent Restoration Module, which employs Residual Mamba Blocks (RMBs) to counteract the degradation caused by the deformation process and enhance the fidelity of the output image. Moreover, a Sparse Mixture-of-Experts (SMoEs) structure is designed to circumvent heavy task competition in multi-task learning due to varying distortions. Extensive experiments demonstrate that our models have achieved state-of-the-art performance compared with other up-to-date methods.",
        "url": "http://arxiv.org/abs/2512.18718v1",
        "published_date": "2025-12-21T12:33:44+00:00",
        "updated_date": "2025-12-21T12:33:44+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Linwei Qiu",
            "Gongzhe Li",
            "Xiaozhe Zhang",
            "Qinlin Sun",
            "Fengying Xie"
        ],
        "tldr": "This paper introduces a unified framework (UniRect) using a Mamba-based architecture for image correction and rectangling, addressing various distortions with a task-agnostic approach.",
        "tldr_zh": "本文介绍了一个统一的框架（UniRect），使用基于Mamba的架构进行图像校正和矩形化，通过与任务无关的方法解决各种失真。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 7
    }
]